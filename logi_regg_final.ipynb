{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = pd.read_csv(\"Classification_train.csv\")\n",
    "x=arr.drop(['label'],axis=1)\n",
    "y=arr['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=x.to_numpy()\n",
    "y_train1=y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(x_train1[:24000])\n",
    "Y_train=np.array(y_train1[:24000])\n",
    "X_test=np.array(x_train1[24000:])\n",
    "Y_test=np.array(y_train1[24000:])\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(p):   \n",
    "    \n",
    "    a=np.zeros(len(p))\n",
    "\n",
    "    if p.max()==p.min():\n",
    "        pass\n",
    "    else:\n",
    "        a=(p-p.mean())/(p.max()-p.min())\n",
    "    return a\n",
    "def normalize(x):\n",
    "    m,n=x.shape\n",
    "    p=np.zeros(n)\n",
    "    x1=np.zeros((m,n))\n",
    "    for i in range(n):\n",
    "        p=x[:,i]\n",
    "        a=norm(p)\n",
    "        x1[:,i]=a\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    m=y.size\n",
    "    n=y.max()+1\n",
    "    p=np.zeros((m,n))\n",
    "    p[np.arange(m),y]=1\n",
    "    return p.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,w,b):\n",
    "  \"\"\"\n",
    "  x:test set array(m,n)\n",
    "  w:feature weights array(n,)\n",
    "  b:bias\n",
    "  \"\"\"\n",
    "  sigmoid= 1/(1+np.exp(-(np.dot(x,w.T)+b)))\n",
    "\n",
    "  return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,w,b):\n",
    "    m,n=x.shape\n",
    "    \n",
    "    f=sigmoid(x,w,b)\n",
    "    loss=-y*np.log(f+1e-15)-(1-y)*np.log(1-f+1e-15)\n",
    "    cost=loss.sum(0)/m\n",
    "    return cost\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,y,w,b):\n",
    "    m,n=x.shape #m is examples, n is features\n",
    "    err=sigmoid(x,w,b)-y\n",
    "    dw=np.dot(err.T,x)/m\n",
    "    db=err.sum(0)/m\n",
    "    return db,dw\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y,w,b,itr_nos,alpha):\n",
    "    m,n=x.shape\n",
    "    for i in range(itr_nos):\n",
    "        db,dw=gradient(x,y,w,b)\n",
    "        w-=alpha*dw\n",
    "        b-=alpha*db\n",
    "        if i%(itr_nos//10)==0:\n",
    "            print(\"epoch: \",i,end=\", \")\n",
    "            print(\"cost: \",cost(x,y,w,b))\n",
    "    return w,b\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(w,b,x_test):\n",
    "    m,n=x_test.shape\n",
    "    p=sigmoid(x_test,w,b)\n",
    "    return p.argmax(1)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y1,y2):\n",
    "    return np.mean(y1==y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm=normalize(X_train)\n",
    "y_hot=one_hot_encoding(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b=gradient_descent(x_norm,y_hot.T,np.random.randn(10,784),np.random.randn(1,10),10000,1)\n",
    "y_predc=prob(w,b,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9764583333333333\n"
     ]
    }
   ],
   "source": [
    "y_predc=prob(w,b,normalize(X_train))\n",
    "print(accuracy(Y_train,y_predc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963\n"
     ]
    }
   ],
   "source": [
    "y_predc=prob(w,b,normalize(X_test))\n",
    "print(accuracy(Y_test,y_predc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
